#!/usr/bin/env python3
"""
Detect objects in scene images using GroundingDINO.

Runs zero-shot object detection on overhead camera images and outputs
detected object positions as JSON. Supports single image files or batch
processing from a manifest generated by extract_first_frames.py.

Usage:
    # Detect objects in a single image
    python scripts/high-level-planner/scan_scene.py \
        --image scripts/high-level-planner/157-episode-1-starting-frame.png \
        --labels "white block" "bowl"

    # Batch mode: process all frames from a manifest
    python scripts/high-level-planner/scan_scene.py \
        --manifest scripts/high-level-planner/frames/manifest.json \
        --labels "white block" "bowl"

    # Save annotated images with bounding boxes
    python scripts/high-level-planner/scan_scene.py \
        --image scripts/high-level-planner/157-episode-1-starting-frame.png \
        --labels "white block" "bowl" \
        --annotate

    # Custom threshold
    python scripts/high-level-planner/scan_scene.py \
        --image scripts/high-level-planner/157-episode-1-starting-frame.png \
        --labels "white block" "bowl" "robot arm" \
        --threshold 0.2
"""

import argparse
import json
import sys
from pathlib import Path

from PIL import Image, ImageDraw, ImageFont

# Add project root to path
PROJECT_ROOT = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(PROJECT_ROOT))

from utils.vision import ObjectDetector

# Distinct colors for bounding boxes
BOX_COLORS = [
    (255, 0, 0),
    (0, 200, 0),
    (0, 100, 255),
    (255, 165, 0),
    (200, 0, 200),
    (0, 200, 200),
    (255, 255, 0),
]


def annotate_image(
    image: Image.Image,
    detections: list[dict],
    label_colors: dict[str, tuple[int, int, int]] | None = None,
) -> Image.Image:
    """Draw bounding boxes and labels on an image.

    Args:
        image: Original PIL image.
        detections: List of detection dicts from ObjectDetector.
        label_colors: Optional mapping of label -> RGB color.

    Returns:
        Annotated copy of the image.
    """
    img = image.copy()
    draw = ImageDraw.Draw(img)
    w, h = img.size

    if label_colors is None:
        unique_labels = list(dict.fromkeys(d["label"] for d in detections))
        label_colors = {
            label: BOX_COLORS[i % len(BOX_COLORS)]
            for i, label in enumerate(unique_labels)
        }

    try:
        font = ImageFont.truetype("arial.ttf", max(14, h // 30))
    except (OSError, IOError):
        font = ImageFont.load_default()

    for det in detections:
        box = det["box"]
        color = label_colors.get(det["label"], (255, 255, 255))
        x1, y1, x2, y2 = box["x1"] * w, box["y1"] * h, box["x2"] * w, box["y2"] * h

        # Draw box
        line_width = max(2, min(w, h) // 200)
        draw.rectangle([x1, y1, x2, y2], outline=color, width=line_width)

        # Draw center dot
        cx, cy = det["center"]["x"] * w, det["center"]["y"] * h
        r = max(3, min(w, h) // 150)
        draw.ellipse([cx - r, cy - r, cx + r, cy + r], fill=color)

        # Draw label
        text = f"{det['label']} {det['confidence']:.2f}"
        draw.text((x1 + 2, y1 - 18), text, fill=color, font=font)

    return img


def process_single_image(
    image_path: Path,
    detector: ObjectDetector,
    labels: list[str],
    threshold: float,
    annotate: bool,
    output_dir: Path | None,
) -> dict:
    """Process a single image and return detection results."""
    image = Image.open(image_path).convert("RGB")
    detections = detector.detect(image, labels, threshold=threshold)
    det_dicts = [d.to_dict() for d in detections]

    result = {
        "image": str(image_path),
        "size": {"width": image.width, "height": image.height},
        "labels_queried": labels,
        "threshold": threshold,
        "num_detections": len(det_dicts),
        "detections": det_dicts,
    }

    # Print summary
    print(f"\n{image_path.name}: {len(detections)} detection(s)")
    for d in detections:
        print(
            f"  {d.label:20s}  center=({d.center[0]:.3f}, {d.center[1]:.3f})  "
            f"conf={d.confidence:.3f}"
        )

    if annotate:
        out_dir = output_dir or image_path.parent
        out_dir.mkdir(parents=True, exist_ok=True)
        annotated = annotate_image(image, det_dicts)
        ann_path = out_dir / f"{image_path.stem}_annotated.png"
        annotated.save(ann_path)
        result["annotated_image"] = str(ann_path)
        print(f"  Annotated: {ann_path}")

    return result


def process_manifest(
    manifest_path: Path,
    detector: ObjectDetector,
    labels: list[str],
    threshold: float,
    annotate: bool,
    output_dir: Path | None,
) -> dict:
    """Process all frames listed in a manifest file."""
    with open(manifest_path) as f:
        manifest = json.load(f)

    frames_dir = manifest_path.parent
    results = []

    for frame in manifest["frames"]:
        image_path = frames_dir / frame["file"]
        if not image_path.exists():
            print(f"WARNING: {image_path} not found, skipping")
            continue

        result = process_single_image(
            image_path, detector, labels, threshold, annotate, output_dir
        )
        result["episode"] = frame.get("episode")
        # Include ground truth if available
        for key in ("duplo_position", "bowl_position"):
            if key in frame:
                result[f"gt_{key}"] = frame[key]
        results.append(result)

    return {
        "dataset": manifest.get("dataset"),
        "camera": manifest.get("camera"),
        "labels_queried": labels,
        "threshold": threshold,
        "num_frames": len(results),
        "frames": results,
    }


def main():
    parser = argparse.ArgumentParser(
        description="Detect objects in scene images using GroundingDINO"
    )
    source = parser.add_mutually_exclusive_group(required=True)
    source.add_argument("--image", type=str, help="Path to a single image file")
    source.add_argument(
        "--manifest",
        type=str,
        help="Path to manifest.json from extract_first_frames.py",
    )
    parser.add_argument(
        "--labels",
        nargs="+",
        default=["white block", "bowl"],
        help="Object labels to detect (default: 'white block' 'bowl')",
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=0.3,
        help="Detection confidence threshold (default: 0.3)",
    )
    parser.add_argument(
        "--annotate",
        action="store_true",
        help="Save annotated images with bounding boxes",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help="Output directory for annotated images (default: same as input)",
    )
    parser.add_argument(
        "--output-json",
        type=str,
        default=None,
        help="Save results to a JSON file",
    )
    parser.add_argument(
        "--model",
        type=str,
        default=None,
        help="HuggingFace model ID (default: IDEA-Research/grounding-dino-tiny)",
    )
    args = parser.parse_args()

    detector = ObjectDetector(model_id=args.model)
    output_dir = Path(args.output_dir) if args.output_dir else None

    if args.image:
        image_path = Path(args.image)
        if not image_path.exists():
            print(f"ERROR: Image not found: {image_path}", file=sys.stderr)
            return 1
        results = process_single_image(
            image_path, detector, args.labels, args.threshold, args.annotate, output_dir
        )
    else:
        manifest_path = Path(args.manifest)
        if not manifest_path.exists():
            print(f"ERROR: Manifest not found: {manifest_path}", file=sys.stderr)
            return 1
        results = process_manifest(
            manifest_path,
            detector,
            args.labels,
            args.threshold,
            args.annotate,
            output_dir,
        )

    # Output JSON
    json_str = json.dumps(results, indent=2)
    if args.output_json:
        out_path = Path(args.output_json)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        with open(out_path, "w") as f:
            f.write(json_str)
        print(f"\nResults saved to {out_path}")
    else:
        print(f"\n{json_str}")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
